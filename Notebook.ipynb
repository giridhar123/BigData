{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project\n",
    "Il progetto consiste dei tizi caio e caio e caio per la predizione delle frodi bla bla di credito bla bla.\n",
    "Ambiente: si è voluto usare bla bla, HDFS, Spark e Pandas.\n",
    "\n",
    "## 1.Inizializzazione dell'ambiente Spark\n",
    "L'inizializzazione dell'ambiente Spark consiste nell'importazione dei relativi moduli e dell'inizializzazione di una nuova SparkSession.\n",
    "\n",
    "PySpark isn't on sys.path by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding pyspark to sys.path at runtime. findspark does the latter.\n",
    "Without any arguments, the SPARK_HOME environment variable will be used, and if that isn't set, other possible install locations will be checked. If you've installed spark with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "location = findspark.find()\n",
    "findspark.init(location)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Progetto BigData Gatto - Lavalle - Ferdico A.A. 2020/2021\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrizione del dataset\n",
    "\n",
    "Il dataset analizzato nel progetto è un insieme di record di transazioni di carte di credito a cui è stato effettuato una PCA. I dati sono raccolti in maniera continua da (@TODO MESE ANNO). Il dataset analizzato presenta circa (@TODO) di record di incidenti al momento dell'analisi in questo progetto.\n",
    "\n",
    "Il dataset è fornito in formato .csv. La tabella seguente ne descrive tutti gli attributi:\n",
    "\n",
    "## TABELLA DATASET CON SPIEGAZIONE DELLE COLONNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importazione del dataset in HDFS\n",
    "\n",
    "COMANDO CLI PER IL CARICAMENTO DEL FILE .CSV IN HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs fs -put nomeFileLocale DirectoryDestinazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lettura del dataset da HDFS con Spark\n",
    "\n",
    "Il codice seguente permette la lettura del file da HDFS e quindi l'importazione del dataset in formato .csv all'interno del dataframe secondo lo schema appena creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = spark.read \\\n",
    "    .csv('hdfs://localhost:9099/creditCardProject/creditcard.csv', header = 'True', inferSchema='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset preprocessing\n",
    "La fase di preprocessing è necessaria per preparare il dataset appena caricato prima dell'analisi vera e propria. I dati presenti possono infatti presentare errori, dati mancanti o valori non previsti. L'obiettivo del preprocessing è quindi quello di pulire tali informazioni rimuovendo o \"curando\" i dati che presentano rumore o qualsiasi altro tipo di inconsistenze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data cleaning\n",
    "Banalmente, la prima operazione può essere quella di individuare le informazioni che presentano caratteristiche con valori mancanti. Il trattamento di valori mancanti può avvenire fondamentalmente in due modi: cancellazione o imputazione. La scelta corretta dipende dall'obiettivo dell'analisi e dalla possibile conoscenza a priori del problema, oltre ovviamente che dalle quantità di tali valori nulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullValues = dataSet.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in dataSet.columns])\n",
    "nullValues.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dall'esecuzione precedente è possibile notare come tutte le features presenti nel dataset non presentino dati mancanti.\n",
    "Una piccola parentesi va invece aperta per l'analisi predittiva. Ricordando che è richiesta la previsione della classe di appartenza di una transazione, le caratteristiche che possono in qualche modo influenzare questo campo andranno sicuramente mantenute. Le operazioni successive andranno ad identificare le feature meno rilevanti e che andremo ad eliminare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertiamo in Pandas per una gestione più semplice per poter fare i grafici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = dataSet.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico X: Amount --> Y: Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Amount']\n",
    "Y = df['Class']\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.scatter(X, Y, marker = \".\", color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possibile dedurre che il dataset è sbilanciato e che le transazioni con class = 1 (frodi) hanno un valore di Amount relativamente basso (< 5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico: X: Time -- Y:Amount (Rosso frode - Blu non frode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico non frode\n",
    "xlim = df['Time'].max() * 1.2\n",
    "ylim = df['Amount'].max() * 1.2\n",
    "\n",
    "X = np.where(df['Class']==0, df['Time'], None)\n",
    "Y = np.where(df['Class']==0, df['Amount'], None)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.scatter(X, Y, marker = \".\", color = \"blue\")\n",
    "\n",
    "X = np.where(df['Class']==1, df['Time'], None)\n",
    "Y = np.where(df['Class']==1, df['Amount'], None)\n",
    "plt.scatter(X, Y, marker = \".\", color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminazione delle features meno rilevanti\n",
    "\n",
    "## Matrice di correlazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# shuffle before creating subsamples\n",
    "\n",
    "df_fraud = df.loc[df.Class == 1]\n",
    "df_non_fraud = df.loc[df.Class == 0][1000:1492]\n",
    "\n",
    "dfFifty = pd.concat([df_fraud, df_non_fraud])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = dfFifty.corr()\n",
    "corr = pd.DataFrame.abs(corr)\n",
    "fig = sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20})\n",
    "fig.set_title('Correlation Matrix', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "soglia = 0.05\n",
    "print(corr[\"Class\"] < soglia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalla matrice di correlazione eliminiamo questo, questo e questo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "df_fraud = df.loc[df.Class == 1]\n",
    "df_non_fraud = df.loc[df.Class == 0][0:492]\n",
    "\n",
    "dfFifty = pd.concat([df_fraud, df_non_fraud])\n",
    "\n",
    "fisherX = np.array(dfFifty.iloc[:, dfFifty.columns != 'Class'])\n",
    "fisherY = np.array(dfFifty.iloc[:, dfFifty.columns == 'Class'])\n",
    "fisherY = fisherY.reshape(1, -1)[0]\n",
    "\n",
    "idx = fisher_score.fisher_score(fisherX, fisherY) #returns rank directly instead of fisher score. so no need for feature_ranking\n",
    "idx = fisher_score.feature_ranking(idx)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal fisher score eliminiamo questo, questo e questo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Salvataggio del dataset cleaned_accidents_dataset.csv\n",
    "E' sicuramente conveniente salvare direttamente nel Drive personale il dataset così ottenuto per non ripetere i passaggi di data cleaning appena descritti ad ogni nuovo accesso a Colab. Per memorizzare il cleaned dataset, è possibile semplicemente utilizzare il metodo .write() fornito da Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importazione del cleaned dataset\n",
    "cleaned_accidents_dataset.csv\n",
    "Andiamo quindi ad importare il nuovo dataset cleaned_accidents_dataset.csv . Per farlo è necessario costruire nuovamente lo schema del dataframe che ospiterà il dataset e infine utilizzare il metodo read di Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisione del dataset in training set e validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analisi predittiva\n",
    "Per il progetto è anche richiesto lo svolgimento dell'analisi predittiva della severità dell’evento incidente sulla base del campo Severity . Il campo Severity indica la gravità di un incidente e l'impatto sul traffico ad esso correlato classificandolo in una di quattro possibili classi con le etichette da 1 a 4 (da minimo impatto sul traffico a massimo impatto). E' chiaro che essendo tali classi etichettate con dei valori finiti, sia possibile una loro predizione attraverso l'utilizzo di un classificatore.\n",
    "\n",
    "#### 6.1 Preliminari analisi predittiva\n",
    "Il primo passaggio per l'analisi predittiva è ovviamente l'importazione di tutte le librerie di Machine Learning dedicate alla creazione di un modello predittivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Scelta delle features\n",
    "Più paragrafi sono stati dedicati alla pulizia del dataset, alla scelta delle features e quindi alla rimozione delle caratteristiche con dati mancanti o palesemente non necessari all'analisi. Per l'analisi predittiva ciò non basta,infatti alcune delle features possono essere in qualche modo implicitamente correlate al campo Severity , e per tale motivo utili alla sua predizione. Un possibile modo per individuare le features correlate è quello di utilizzare l'approccio statistico.\n",
    "Calcolare le correlazioni tra la caratteristica Severity ed il resto è possibile calcolando la relativa matrice di correlazione. E' chiaro quindi che vanno escluse tutte le caratteristiche aventi una correlazione col campo preso in esame al di sotto di una certa soglia.\n",
    "Per poter carcolare la matrice di correlazione, è possibile utilizzare un metodo fornito da Pandas. E' quindi necessario importare il dataset indicizzato all'interno di un suo dataframe:\n",
    "\n",
    "Dalla matrice di correlazione appena ottenuta, va presa in considerazione soltanto la prima colonna ovvero quella relativa alle correlazioni tra la caratteristica Severity e ognuna delle altre caratteristiche.\n",
    "Tanto è maggiore in valore assoluto la correlazione tra due variabili aleatorie, tanto più la conoscenza del valore di una è utile a prevedere il valore dell'altra. Per tale motivo è necessario calcolare i valori assoluti delle correlazioni tra\n",
    "Severity e le altre caratteristiche, ed infine ordinarli in ordine decrescente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.8 Bilanciamento delle classi di Severity\n",
    "Prima di continuare è necessario anche analizzare il bilanciamento delle classi appartenenti alla caratteristica Severity :\n",
    "\n",
    "Il risulta mostra un bilanciamento non proprio uniforme. In particolare è possibile notare come la classe 1 e 4 sono quelle meno frequenti rispetto alle altre presenti. E' possibile bilanciare la distribuzione di tali classi attraverso l'oversampling. L'oversampling consiste nella duplicazione dei record delle le classi meno frequenti. Di conseguenza, va utilizzato il metodo .sample fornito sempre da Spark. Il metodo appena citato permette di specificare una frazione di record da estrarre dal dataframe da cui estrarre i campioni, con o senza sostituzione. L'oversampling sarà effettuato esclusivamente del training set per non influenzare i risultati della predizione da parte del modello.\n",
    "Visuliazziamo la distribuzione delle classi per la stessa caratteristica ma soltanto per il Training Set:\n",
    "\n",
    "Proviamo quindi a distribuire in maniera più uniforme tali classi tramite oversampling. E' evidente che l'oversampling debba essere seguito sui record aventi classi 1 , 3 e 4 di Severity .\n",
    "Bisogna innanzitutto separare i record appartenenti alle stesse classe di Severity:\n",
    "\n",
    "Come descritto prima, è necessario l'oversampling sui record appartenenti alle classi 1 , 3 e 4 . Il fattore di oversampling è gestibile tramite il parametro fraction di sample .\n",
    "\n",
    "Controlliamo quindi se la distribuzione delle classi all'interno del dataset si è uniformata:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dell'errore del modello ottenuto al passo precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = df.drop([\"Time\", \"V3\", \"V6\", \"V11\", \"V14\"], axis = 1) # <-- dal fisher score\n",
    "dfFinal = dfFinal.drop([\"V13\", \"V23\"], axis = 1) # <-- dalla matrice di correlazione\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "standardScaler = preprocessing.StandardScaler()\n",
    "scaledTime = standardScaler.fit_transform(X = dfFinal[['Time']])\n",
    "scaledAmount = standardScaler.fit_transform(X = dfFinal[['Amount']])\n",
    "\n",
    "dfFinal['ScaledTime'] = scaledTime\n",
    "dfFinal['ScaledAmount'] = scaledAmount\n",
    "\n",
    "dfFinal = dfFinal.drop(['Time', 'Amount', 'ScaledTime'], axis = 1)\n",
    "\n",
    "X = dfFinal.iloc[:, dfFinal.columns != 'Class']\n",
    "y = dfFinal.iloc[:, dfFinal.columns == 'Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#hidden_layer_sizes=(200,)\n",
    "MLPC = MLPClassifier(hidden_layer_sizes=(200,6), max_iter=10000, verbose=True)\n",
    "MLPC.fit(X_train, y_train.values.ravel())\n",
    "y_pred = MLPC.predict(X_test)\n",
    "# Obtenemos valores de recall\n",
    "recall_acc = recall_score(y_test, y_pred)\n",
    "print(recall_acc)\n",
    "print(MLPC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1result = f1_score(y_test, y_pred)\n",
    "print(f1result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.9 Training\n",
    "Per l'addestramento è necessario importare i modelli da addestrare dalle librerie di Spark per la classificazione. Come modelli verranno utilizzati Decision Tree ed il classificatore di tipo probabilistico Naive Bayes per poter confrontare infine i risultati ottenuti.\n",
    "Per poter inizializzare i modelli è necessario prima inserire come parametri la caratteristica che il modello deve predire Severity , e la colonna delle features .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfFinal = df.drop([\"Time\", \"V3\", \"V6\", \"V11\", \"V14\"], axis = 1) # <-- dal fisher score\n",
    "dfFinal = dfFinal.drop([\"V13\", \"V23\"], axis = 1) # <-- dalla matrice di correlazione\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "features = dfFinal[dfFinal.columns[:len(dfFinal.columns)-1]].to_numpy()\n",
    "targets = dfFinal.Class.to_numpy()\n",
    "#features, targets = SMOTE().fit_resample(features,targets)\n",
    "#targets = targets.reshape(-1,1)\n",
    "\n",
    "target_un,count = np.unique(targets,return_counts=True)\n",
    "plt.title(\"Class Balancing\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.bar([str(i) for i in target_un],count)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Feature size :  199364\n",
      "Train Label size   : 199364\n",
      "Test Feature size  : 85443\n",
      "Test Label size    : 85443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features, targets, test_size=0.3, shuffle=True)\n",
    "\n",
    "print(\"Train Feature size : \", len(X_train))\n",
    "print(\"Train Label size   :\", len(Y_train))\n",
    "print(\"Test Feature size  :\", len(X_test))\n",
    "print(\"Test Label size    :\", len(Y_test))\n",
    "\n",
    "#SOVRACAMPIONAMENTO SOLO DEL TRAINING SET IN MODO DA SBAGLIARE SOLO 1 VOLTA E NON N VOLTE NEL TEST SET\n",
    "X_train, Y_train = SMOTE().fit_resample(X_train,Y_train)\n",
    "Y_train = Y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, criterion=\"entropy\")\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredetto = model.predict(X_train)\n",
    "testPredetto = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(Y_test, testPredetto, labels=[0, 1])\n",
    "\n",
    "cmatrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non Frode\",\"Frode\"])\n",
    "cmatrix.plot()\n",
    "plt.title(\"Matrice di Confusione\")\n",
    "plt.show()\n",
    "\n",
    "veriNegativi = cm[0][0]\n",
    "veriPositivi = cm[1][1]\n",
    "falsiPositivi = cm[0][1]\n",
    "falsiNegativi = cm[1][0]\n",
    "\n",
    "nonFrodiTotali = veriNegativi + falsiPositivi\n",
    "frodiTotali = veriPositivi + falsiNegativi\n",
    "\n",
    "percentualeDiSuccessoNonFrodi = veriNegativi / nonFrodiTotali\n",
    "percentualeDiSuccessoFrodi = veriPositivi / frodiTotali\n",
    "\n",
    "print(\"Train score     : {:.2f} %\".format(accuracy_score(trainPredetto, Y_train) * 100))\n",
    "print(\"Test score      : {:.2f} %\".format(accuracy_score(testPredetto, Y_test) * 100))\n",
    "print(\"Accuratezza riconoscimento frodi : {:.2f} %\".format(percentualeDiSuccessoFrodi*100))\n",
    "print(\"Accuratezza riconoscimento non frodi : {:.2f} %\".format(percentualeDiSuccessoNonFrodi*100))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall score sul test set     : {:.2f} %\".format(recall_score(testPredetto, Y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10 Prediction e valutazione dei modelli\n",
    "Ora che i modelli sono stati addestrati, è finalmente possibile iniziare la predizione di Severity utilizzando il test set. Di conseguenza, viene utilizzato il metodo .transform() che restituisce direttamente il dataframe contenente la predizione dei modelli utilizzati e la relativa label corretta.\n",
    "Per la valutazione dei modelli appena addestrati, vengono utilizzate le metriche fornite dalle librerie Scikit-learn , ovvero librerie di machine learning open-source scritte in Python.\n",
    "Tutte le metriche fornite dalle librerie da Scikit-learn utilizzano come parametri di input y_true e y_pred . Queste rappresentano rispettivamente le label verità e le label predette dal classificatore. Tali parametri possono essere prelevati direttamente dai dataframe ottenuti nel passaggio precedente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10.1 Accuracy\n",
    "L'accuratezza è semplicemente la percentuale delle istanze classificate correttamente. Calcoliamo quindi l'accuracy dei modelli addestrati:\n",
    "\n",
    "### 6.10.2 Balanced Accuracy\n",
    "Nei casi in cui il dataset non sia bilanciato nel migliore dei modi, come nel nostro caso, ha senso anche la valutazione della balanced accuracy che calcola la media aritmetica delle accuratezze specifiche delle classi:\n",
    "\n",
    "### 6.10.3 F1 Micro\n",
    "Valutazione della F1 micro dei modelli addestrati:\n",
    "\n",
    "### 6.10.4 F1 Macro\n",
    "Valutazione della F1 macro dei modelli addestrati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frodiTotali + nonFrodiTotali)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17f1067490f984ba715149d06ea4a88ce507d8a2668e250361db3c636d63351c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('mongoDB': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
